{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Read the Tensorflow protobuf file (containing weights)\n",
    "Extract all the weights and dump to disk (json encoded numbers)\n",
    "Each node has one coresponding weight file if tensor_content\n",
    "\"\"\"\n",
    "\n",
    "import os.path\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import tensor_util\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# parameter ==========================\n",
    "wkdir = '../../data'\n",
    "pb_filename = 'model.pb'\n",
    "pbtxt_filename = 'model.pbtxt'\n",
    "\n",
    "output_dir = os.path.join(wkdir, 'tensor_weights')\n",
    "os.system(\"mkdir -p \" + output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-a7d7f1ca6758>:8: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "(3, 3, 1, 32)\n",
      "../../data/tensor_weights/conv2d_1_kernel.kw\n",
      "(32,)\n",
      "../../data/tensor_weights/conv2d_1_bias.kw\n",
      "(3, 3, 32, 64)\n",
      "../../data/tensor_weights/conv2d_2_kernel.kw\n",
      "(64,)\n",
      "../../data/tensor_weights/conv2d_2_bias.kw\n",
      "(9216, 128)\n",
      "../../data/tensor_weights/dense_1_kernel.kw\n",
      "(128,)\n",
      "../../data/tensor_weights/dense_1_bias.kw\n",
      "(128, 10)\n",
      "../../data/tensor_weights/dense_2_kernel.kw\n",
      "(10,)\n",
      "../../data/tensor_weights/dense_2_bias.kw\n",
      "Completed. All kernal weights saved to disk.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "# For store the result file (before JSON encoding)\n",
    "result = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # load model from pb file\n",
    "    with gfile.FastGFile(wkdir+'/'+pb_filename,'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        sess.graph.as_default()\n",
    "        g_in = tf.import_graph_def(graph_def)\n",
    "    # write to tensorboard (check tensorboard for each op names)\n",
    "    writer = tf.summary.FileWriter(wkdir+'/log/')\n",
    "    writer.add_graph(sess.graph)\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "    \n",
    "    for i, node in enumerate(graph_def.node):\n",
    "        # only care about those node has tensor_content\n",
    "        if ('value' in node.attr):\n",
    "            # skip training variables\n",
    "            if (\"training\" in node.name):\n",
    "                continue\n",
    "    \n",
    "            if (len(node.attr['value'].tensor.tensor_content)):\n",
    "                tensor_np = tensor_util.MakeNdarray(node.attr['value'].tensor)\n",
    "                tensor_size = tensor_np.shape\n",
    "                \n",
    "                # verify nditer's expected behavior\n",
    "                print(tensor_size)\n",
    "                nditer_verifier_data = []\n",
    "                if (len(tensor_size) == 4):\n",
    "                    for i in range(tensor_size[0]):\n",
    "                        for j in range(tensor_size[1]):\n",
    "                            for k in range(tensor_size[2]):\n",
    "                                for w in range(tensor_size[3]):\n",
    "                                    nditer_verifier_data.append(tensor_np[i,j,k,w].item())\n",
    "                # save the data\n",
    "                result = {}\n",
    "                result['name'] = node.name\n",
    "                result['shape'] = tensor_size\n",
    "                result['tensor_content'] = []\n",
    "                for i, x in enumerate(np.nditer(tensor_np)):\n",
    "                    result['tensor_content'].append(x.item())\n",
    "                    \n",
    "                    # verify nditer data\n",
    "                    if (len(tensor_size) == 4):\n",
    "                        if (x.item() != nditer_verifier_data[i]):\n",
    "                            print(\"[WARN] nditer verifier failed. \")\n",
    "                \n",
    "                # parse the name (each node name contains NN layer name + type_name[kernal/bias])\n",
    "                layer_name = node.name.split(\"/\")[0]\n",
    "                type_name = node.name.split(\"/\")[1]\n",
    "                \n",
    "                # kernal weights\n",
    "                output_fname = os.path.join(output_dir, layer_name + \"_\" + type_name) + \".kw\"\n",
    "                print(output_fname)\n",
    "                with open(output_fname, 'w') as outfile:  \n",
    "                    json.dump(result, outfile)\n",
    "                \n",
    "    print(\"Completed. All kernal weights saved to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
